name: Reusable Storybook Tests with Regression Analysis

on:
  workflow_call:
    inputs:
      node-version:
        description: "Node.js version to use for Storybook tests"
        required: false
        type: string
        default: "18.x"
      storybook_port:
        description: "Port for Storybook server"
        required: false
        type: string
        default: "3001"
      target_branch_to_compare:
        description: "The target branch to compare against for regressions (e.g., main). If empty, regression check is skipped."
        required: false
        type: string
        default: ""
      runs_on:
        required: false
        type: string
        default: "self-hosted"
    outputs:
      pr_has_errors:
        description: "Boolean indicating if the PR branch has Storybook test errors."
        value: ${{ jobs.test-pr-branch-storybook.outputs.has_errors }}
      pr_failing_stories_json:
        description: "JSON list of failing story IDs on the PR branch."
        value: ${{ jobs.test-pr-branch-storybook.outputs.failing_stories_json }}
      has_regressions:
        description: "Boolean indicating if Storybook test regressions were found."
        value: ${{ jobs.compare-results.outputs.has_regressions }}
      regression_count:
        description: "Number of Storybook test regressions found."
        value: ${{ jobs.compare-results.outputs.regression_count }}

jobs:
  lint:
    uses: ./.github/workflows/test-ts-lint.yml # Assumes JS/TS linting for Storybook setup
    permissions:
      contents: write

  test-target-branch-storybook:
    if: ${{ inputs.target_branch_to_compare != '' }}
    name: Test Target Branch Stories
    needs: [lint] # Ensure linting passes before running tests
    runs-on: ${{ inputs.runs_on }}
    outputs:
      total: ${{ steps.normalise-target.outputs.total }}
      passed: ${{ steps.normalise-target.outputs.passed }}
      percentage: ${{ steps.normalise-target.outputs.percentage }}
      passing_stories_json: ${{ steps.normalise-target.outputs.passing_items_json }}
      collection_errors: ${{ steps.normalise-target.outputs.collection_errors }}
      no_tests_found: ${{ steps.normalise-target.outputs.no_tests_found }}
    steps:
      - name: Checkout Target Branch
        uses: actions/checkout@v4.2.2
        with:
          ref: ${{ inputs.target_branch_to_compare }}
          submodules: "recursive"

      - name: Use Node.js ${{ inputs.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ inputs.node-version }}
          cache: "npm"

      - name: Install dependencies (Target)
        run: npm ci

      - name: Install Playwright browsers (Target)
        run: npx playwright install --with-deps

      - name: Run Storybook (Target)
        run: npm run storybook -- --port ${{ inputs.storybook_port }} &

      - name: Wait for Storybook (Target)
        run: |
          echo "Waiting for Storybook (Target) to start on port ${{ inputs.storybook_port }}..."
          timeout=120 # Increased timeout
          counter=0
          until $(curl --output /dev/null --silent --head --fail http://localhost:${{ inputs.storybook_port }}); do
            if [ $counter -ge $timeout ]; then # Use -ge for counter check
              echo "Timed out waiting for Storybook (Target) to start"
              exit 1
            fi
            echo "Waiting for Storybook (Target)... ($counter seconds so far)"
            sleep 5
            counter=$((counter + 5))
          done
          echo "Storybook (Target) is up and running on port ${{ inputs.storybook_port }}!"

      - name: Run Storybook tests (Target)
        id: run-tests-target
        run: |
          npm run storybook-test -- --json-report target_storybook_results.json || true
          echo "Storybook tests on target branch completed."
          if [ -f target_storybook_results.json ]; then
            cat target_storybook_results.json
          else
            echo "target_storybook_results.json not found."
            echo "{\"testResults\": [], \"numTotalTests\": 0, \"numPassedTests\": 0}" > target_storybook_results.json # Create empty results
          fi

      - name: Normalise Storybook results (Target)
        id: normalise-target
        run: |
          python "$GITHUB_WORKSPACE/.github/scripts/storybook_results_to_standard_json.py" \
            target_storybook_results.json \
            target_test_data.json \
            --github-output "$GITHUB_OUTPUT"

      - name: Upload target branch artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: target_branch_data_${{ github.event.pull_request.number || github.run_id }}
          path: |
            target_test_data.json
            target_storybook_results.json
          retention-days: 3
          if-no-files-found: ignore

  test-pr-branch-storybook:
    name: Test PR Branch Stories
    needs: [lint]
    runs-on: ${{ inputs.runs_on }}
    outputs:
      has_errors: ${{ steps.run-tests-pr.outcome == 'failure' || steps.normalise-pr.outputs.has_failures == 'true' }}
      failing_stories_json: ${{ steps.normalise-pr.outputs.failing_items_json }}
      total: ${{ steps.normalise-pr.outputs.total }}
      passed: ${{ steps.normalise-pr.outputs.passed }}
      percentage: ${{ steps.normalise-pr.outputs.percentage }}
      collection_errors: ${{ steps.normalise-pr.outputs.collection_errors }}
      no_tests_found: ${{ steps.normalise-pr.outputs.no_tests_found }}
    steps:
      - name: Checkout Repository (PR)
        uses: actions/checkout@v4.2.2
        with:
          submodules: "recursive"

      - name: Use Node.js ${{ inputs.node-version }}
        uses: actions/setup-node@v4 # Use v4 consistently
        with:
          node-version: ${{ inputs.node-version }}
          cache: "npm"

      - name: Install dependencies (PR)
        run: npm ci

      - name: Install Playwright browsers (PR)
        run: npx playwright install --with-deps

      - name: Run Storybook (PR)
        run: npm run storybook -- --port ${{ inputs.storybook_port }} &

      - name: Wait for Storybook (PR)
        run: |
          echo "Waiting for Storybook (PR) to start on port ${{ inputs.storybook_port }}..."
          timeout=120 # Increased timeout
          counter=0
          until $(curl --output /dev/null --silent --head --fail http://localhost:${{ inputs.storybook_port }}); do
            if [ $counter -ge $timeout ]; then # Use -ge
              echo "Timed out waiting for Storybook (PR) to start"
              exit 1
            fi
            echo "Waiting for Storybook (PR)... ($counter seconds so far)"
            sleep 5
            counter=$((counter + 5))
          done
          echo "Storybook (PR) is up and running on port ${{ inputs.storybook_port }}!"

      - name: Run Storybook tests (PR)
        id: run-tests-pr
        run: |
          npm run storybook-test -- --json-report pr_storybook_results.json || true
          echo "Storybook tests on PR branch completed."
          if [ -f pr_storybook_results.json ]; then
            cat pr_storybook_results.json
          else
            echo "pr_storybook_results.json not found."
            echo "{\"testResults\": [], \"numTotalTests\": 0, \"numPassedTests\": 0, \"numFailedTests\": 0}" > pr_storybook_results.json # Create empty results
          fi

      - name: Normalise Storybook results (PR)
        id: normalise-pr
        run: |
          python "$GITHUB_WORKSPACE/.github/scripts/storybook_results_to_standard_json.py" \
            pr_storybook_results.json \
            pr_test_data.json \
            --github-output "$GITHUB_OUTPUT"

      - name: Upload PR branch artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pr_branch_data_${{ github.event.pull_request.number || github.run_id }}
          path: |
            pr_test_data.json
            pr_storybook_results.json
            ./*-snapshots/
            ./coverage/
          retention-days: 7
          if-no-files-found: ignore

  compare-results:
    if: ${{ inputs.target_branch_to_compare != '' }}
    needs: [test-target-branch-storybook, test-pr-branch-storybook]
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch_to_compare }}
      baseline_results_artifact: target_branch_data_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: target_test_data.json
      current_label: ${{ github.head_ref || github.ref_name || 'source branch' }}
      current_results_artifact: pr_branch_data_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: pr_test_data.json
      baseline_passed: ${{ needs.test-target-branch-storybook.outputs.passed || '0' }}
      baseline_total: ${{ needs.test-target-branch-storybook.outputs.total || '0' }}
      baseline_percentage: ${{ needs.test-target-branch-storybook.outputs.percentage || '0' }}
      current_passed: ${{ needs.test-pr-branch-storybook.outputs.passed || '0' }}
      current_total: ${{ needs.test-pr-branch-storybook.outputs.total || '0' }}
      current_percentage: ${{ needs.test-pr-branch-storybook.outputs.percentage || '0' }}
      baseline_collection_errors: ${{ needs.test-target-branch-storybook.outputs.collection_errors || 'false' }}
      baseline_no_tests_found: ${{ needs.test-target-branch-storybook.outputs.no_tests_found || 'false' }}
      current_collection_errors: ${{ needs.test-pr-branch-storybook.outputs.collection_errors || 'false' }}
      current_no_tests_found: ${{ needs.test-pr-branch-storybook.outputs.no_tests_found || 'false' }}
      artifact_name: regression_details_pr_${{ github.event.pull_request.number || github.run_id }}_storybook

  perform-regression-analysis:
    if: ${{ inputs.target_branch_to_compare != '' }}
    needs: [test-target-branch-storybook, test-pr-branch-storybook]
    uses: ./.github/workflows/meta-regression-analysis.yml
    with:
      item_type_singular: "Storybook story"
      item_type_plural: "Storybook stories"
      pr_number: ${{ github.event.pull_request.number }}
      run_id: ${{ github.run_id }}
      target_branch_artifact_name: target_branch_data_${{ github.event.pull_request.number || github.run_id }}
      pr_branch_artifact_name: pr_branch_data_${{ github.event.pull_request.number || github.run_id }}

  check-storybook-results:
    name: Check Storybook Results & Regressions
    runs-on: ${{ inputs.runs_on }}
    needs:
      [test-pr-branch-storybook, compare-results, perform-regression-analysis]
    if: always() # Always run to give a final status
    steps:
      - name: Evaluate Storybook Test Results
        run: |
          PR_HAS_ERRORS="${{ needs.test-pr-branch-storybook.outputs.has_errors }}"
          REGRESSION_ANALYSIS_INTENDED="${{ inputs.target_branch_to_compare != '' }}"
          HAS_REGRESSIONS="false"
          REGRESSION_COUNT="0"

          echo "--- Storybook Test Results ---"
          echo "PR Branch Storybook Test Errors: $PR_HAS_ERRORS"
          echo "Target Branch for Comparison: ${{ inputs.target_branch_to_compare }}"

          if [[ "$REGRESSION_ANALYSIS_INTENDED" == "true" ]]; then
            if [[ "${{ needs.compare-results.result }}" != "skipped" ]]; then
              HAS_REGRESSIONS="${{ needs.compare-results.outputs.has_regressions }}"
              REGRESSION_COUNT="${{ needs.compare-results.outputs.regression_count }}"
              echo "Storybook Regressions Found: $HAS_REGRESSIONS ($REGRESSION_COUNT)"
            else
              echo "Storybook regression analysis job was skipped."
            fi

            if [[ "$HAS_REGRESSIONS" == "true" ]]; then
              echo "::error::${REGRESSION_COUNT} Storybook test(s) regressed. Stories that were passing on target branch ('${{ inputs.target_branch_to_compare }}') are now failing/broken on the PR branch."
              # Consider downloading and displaying the regression artifact for details.
              exit 1 # Fail the workflow due to regressions
            fi
          fi

          # If no regression analysis, or if regression analysis passed, check PR errors directly
          if [[ "$PR_HAS_ERRORS" == "true" ]]; then
            echo "::error::Storybook tests failed on the PR branch. Check afor artifacts."
            # The original test job might have already failed, this ensures it.
            exit 1
          fi

          echo "✅ Storybook tests passed and no new regressions detected (if applicable)."
          echo "--- End Storybook Test Results ---"
