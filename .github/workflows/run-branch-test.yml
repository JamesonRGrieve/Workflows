name: Run Branch Tests with Regression Detection

on:
  workflow_call:
    inputs:
      target_branch:
        description: "Target branch to compare against (e.g., main)."
        required: true
        type: string
      # Python/pytest options
      python-version:
        description: "Python version for pytest."
        required: false
        type: string
        default: "3.10"
      # Node.js options for Jest/Mocha
      node-version:
        description: "Node.js version for Jest/Mocha."
        required: false
        type: string
        default: "18"
      # Rust/cargo options
      rust-version:
        description: "Rust toolchain version for cargo test."
        required: false
        type: string
        default: "stable"
      # .NET options
      dotnet-version:
        description: ".NET SDK version for NUnit/xUnit tests."
        required: false
        type: string
        default: "8.0.x"
      # C++/CMake options
      cmake-version:
        description: "CMake version for C++ tests."
        required: false
        type: string
        default: "3.28"
      cpp-compiler:
        description: "C++ compiler (gcc, clang). Auto-detects if empty."
        required: false
        type: string
        default: ""
      cpp-build-type:
        description: "CMake build type (Debug, Release, RelWithDebInfo, MinSizeRel)."
        required: false
        type: string
        default: "Release"
      cpp-build-dir:
        description: "Build directory for C++ projects."
        required: false
        type: string
        default: "build"
      cpp-cmake-args:
        description: "Additional CMake configuration arguments."
        required: false
        type: string
        default: ""
      cpp-test-args:
        description: "Additional CTest arguments."
        required: false
        type: string
        default: ""
      # Common options
      runs_on:
        description: "Runner label."
        required: false
        type: string
        default: '["self-hosted", "multithreaded"]'
      parallel_workers:
        description: "Number of parallel workers. Leave empty for auto-detect (6 for multithreaded, 1 for singlethreaded). Use 'auto' for cgroup-aware CPU count."
        required: false
        type: string
        default: ""
      use_target_cache:
        description: "Whether to use caching for target branch test results. When false, always runs fresh tests."
        required: false
        type: boolean
        default: false
      # Jest options
      jest-command:
        description: "Base command used to invoke Jest."
        required: false
        type: string
        default: "npx jest"
      jest-extra-args:
        description: "Additional arguments to pass to Jest."
        required: false
        type: string
        default: ""
      # Mocha options
      mocha-command:
        description: "Base command used to invoke Mocha."
        required: false
        type: string
        default: "npx mocha"
      mocha-extra-args:
        description: "Additional arguments to pass to Mocha."
        required: false
        type: string
        default: ""
      working-directory:
        description: "Directory where JS test commands should be executed."
        required: false
        type: string
        default: "."
      # Python unittest options
      unittest-start-directory:
        description: "Directory passed to unittest discovery."
        required: false
        type: string
        default: "."
      unittest-test-pattern:
        description: "Pattern used by unittest discovery."
        required: false
        type: string
        default: "test*.py"
      # Storybook options
      storybook-port:
        description: "Port for Storybook server."
        required: false
        type: string
        default: "6006"
      storybook-start-command:
        description: "Command to start Storybook server."
        required: false
        type: string
        default: "npm run storybook"
      storybook-test-command:
        description: "Command to run Storybook tests."
        required: false
        type: string
        default: "npm run storybook-test"
    secrets:
      DISCORD_WEBHOOK_URL:
        required: false
      DISCORD_USER_MAP:
        required: false
    outputs:
      has_regressions:
        description: "Whether regressions were detected (any framework)"
        value: ${{ jobs.aggregate-results.outputs.has_regressions }}
      regression_count:
        description: "Total number of regressions (all frameworks)"
        value: ${{ jobs.aggregate-results.outputs.regression_count }}
      has_regressions_cargo:
        description: "Whether regressions were detected (cargo)"
        value: ${{ jobs.cargo-compare.outputs.has_regressions }}
      regression_count_cargo:
        description: "Number of regressions (cargo)"
        value: ${{ jobs.cargo-compare.outputs.regression_count }}
      cpp_has_regressions:
        description: "Whether regressions were detected (C++)"
        value: ${{ jobs.cpp-compare.outputs.has_regressions }}
      cpp_regression_count:
        description: "Number of regressions (C++)"
        value: ${{ jobs.cpp-compare.outputs.regression_count }}
      nunit_has_regressions:
        description: "Whether regressions were detected (NUnit)"
        value: ${{ jobs.nunit-compare.outputs.has_regressions }}
      nunit_regression_count:
        description: "Number of regressions (NUnit)"
        value: ${{ jobs.nunit-compare.outputs.regression_count }}
      xunit_has_regressions:
        description: "Whether regressions were detected (xUnit)"
        value: ${{ jobs.xunit-compare.outputs.has_regressions }}
      xunit_regression_count:
        description: "Number of regressions (xUnit)"
        value: ${{ jobs.xunit-compare.outputs.regression_count }}
      unittest_has_regressions:
        description: "Whether regressions were detected (unittest)"
        value: ${{ jobs.unittest-compare.outputs.has_regressions }}
      unittest_regression_count:
        description: "Number of regressions (unittest)"
        value: ${{ jobs.unittest-compare.outputs.regression_count }}
      storybook_has_regressions:
        description: "Whether regressions were detected (Storybook)"
        value: ${{ jobs.storybook-compare.outputs.has_regressions }}
      storybook_regression_count:
        description: "Number of regressions (Storybook)"
        value: ${{ jobs.storybook-compare.outputs.regression_count }}

jobs:
  # Detect which test frameworks are present
  detect-frameworks:
    runs-on: ${{ fromJSON(inputs.runs_on) }}
    outputs:
      has_pytest: ${{ steps.detect.outputs.has_pytest }}
      has_jest: ${{ steps.detect.outputs.has_jest }}
      has_mocha: ${{ steps.detect.outputs.has_mocha }}
      has_cargo: ${{ steps.detect.outputs.has_cargo }}
      has_cpp: ${{ steps.detect.outputs.has_cpp }}
      has_nunit: ${{ steps.detect.outputs.has_nunit }}
      has_xunit: ${{ steps.detect.outputs.has_xunit }}
      has_unittest: ${{ steps.detect.outputs.has_unittest }}
      has_storybook: ${{ steps.detect.outputs.has_storybook }}
    steps:
      - uses: actions/checkout@v4.2.2
      - name: Detect test frameworks
        id: detect
        run: |
          # Detect pytest
          if [ -f "pyproject.toml" ] || [ -f "setup.py" ] || [ -f "requirements.txt" ] || find . -name "test_*.py" -o -name "*_test.py" 2>/dev/null | head -1 | grep -q .; then
            echo "has_pytest=true" >> "$GITHUB_OUTPUT"
            echo "✅ Detected: pytest"
          else
            echo "has_pytest=false" >> "$GITHUB_OUTPUT"
          fi

          # Detect cargo (Rust)
          if [ -f "Cargo.toml" ]; then
            echo "has_cargo=true" >> "$GITHUB_OUTPUT"
            echo "✅ Detected: cargo (Rust)"
          else
            echo "has_cargo=false" >> "$GITHUB_OUTPUT"
          fi

          # Detect C++ with CMake and tests
          HAS_CPP="false"
          if [ -f "CMakeLists.txt" ]; then
            # Check for test-related CMake content
            if grep -rqE "(enable_testing|add_test|gtest|catch|boost.*test)" CMakeLists.txt 2>/dev/null || \
               find . -name "CMakeLists.txt" -exec grep -lE "(enable_testing|add_test|gtest|catch)" {} \; 2>/dev/null | head -1 | grep -q .; then
              HAS_CPP="true"
              echo "✅ Detected: C++ (CMake with tests)"
            fi
          fi
          # Check for test source files
          if [ "$HAS_CPP" = "false" ]; then
            if find . \( -name "*_test.cpp" -o -name "*_test.cc" -o -name "test_*.cpp" -o -name "test_*.cc" \) 2>/dev/null | head -1 | grep -q .; then
              HAS_CPP="true"
              echo "✅ Detected: C++ test files"
            fi
          fi
          echo "has_cpp=$HAS_CPP" >> "$GITHUB_OUTPUT"

          # Detect Jest
          HAS_JEST="false"
          if [ -f "package.json" ]; then
            # Check for jest in dependencies or devDependencies
            if grep -q '"jest"' package.json 2>/dev/null; then
              HAS_JEST="true"
            fi
            # Check for jest config files
            if [ -f "jest.config.js" ] || [ -f "jest.config.ts" ] || [ -f "jest.config.mjs" ] || [ -f "jest.config.cjs" ] || [ -f "jest.config.json" ]; then
              HAS_JEST="true"
            fi
            # Check for jest section in package.json
            if grep -q '"jest":' package.json 2>/dev/null; then
              HAS_JEST="true"
            fi
          fi
          echo "has_jest=$HAS_JEST" >> "$GITHUB_OUTPUT"
          if [ "$HAS_JEST" = "true" ]; then
            echo "✅ Detected: Jest"
          fi

          # Detect Mocha
          HAS_MOCHA="false"
          if [ -f "package.json" ]; then
            # Check for mocha in dependencies or devDependencies
            if grep -q '"mocha"' package.json 2>/dev/null; then
              HAS_MOCHA="true"
            fi
            # Check for mocha config files
            if [ -f ".mocharc.js" ] || [ -f ".mocharc.json" ] || [ -f ".mocharc.yml" ] || [ -f ".mocharc.yaml" ] || [ -f ".mocharc.cjs" ] || [ -f ".mocharc.mjs" ]; then
              HAS_MOCHA="true"
            fi
            # Check for mocha section in package.json
            if grep -q '"mocha":' package.json 2>/dev/null; then
              HAS_MOCHA="true"
            fi
          fi
          echo "has_mocha=$HAS_MOCHA" >> "$GITHUB_OUTPUT"
          if [ "$HAS_MOCHA" = "true" ]; then
            echo "✅ Detected: Mocha"
          fi

          # Detect NUnit (.NET)
          HAS_NUNIT="false"
          if find . -name "*.csproj" 2>/dev/null | head -1 | grep -q .; then
            if grep -rq "NUnit" *.csproj 2>/dev/null || grep -rq "nunit" . --include="*.csproj" 2>/dev/null; then
              HAS_NUNIT="true"
            fi
          fi
          echo "has_nunit=$HAS_NUNIT" >> "$GITHUB_OUTPUT"
          if [ "$HAS_NUNIT" = "true" ]; then
            echo "✅ Detected: NUnit (.NET)"
          fi

          # Detect xUnit (.NET)
          HAS_XUNIT="false"
          if find . -name "*.csproj" 2>/dev/null | head -1 | grep -q .; then
            if grep -rq "xunit" . --include="*.csproj" 2>/dev/null; then
              HAS_XUNIT="true"
            fi
          fi
          echo "has_xunit=$HAS_XUNIT" >> "$GITHUB_OUTPUT"
          if [ "$HAS_XUNIT" = "true" ]; then
            echo "✅ Detected: xUnit (.NET)"
          fi

          # Detect Python unittest (when pytest is not present)
          HAS_UNITTEST="false"
          if [ -f "pyproject.toml" ] || [ -f "setup.py" ] || find . -name "test_*.py" 2>/dev/null | head -1 | grep -q .; then
            # Only enable unittest if pytest is NOT detected (pytest is preferred)
            if ! grep -q "pytest" requirements.txt 2>/dev/null && ! grep -q "pytest" pyproject.toml 2>/dev/null; then
              # Check for unittest imports
              if grep -rq "import unittest" . --include="*.py" 2>/dev/null || grep -rq "from unittest" . --include="*.py" 2>/dev/null; then
                HAS_UNITTEST="true"
              fi
            fi
          fi
          echo "has_unittest=$HAS_UNITTEST" >> "$GITHUB_OUTPUT"
          if [ "$HAS_UNITTEST" = "true" ]; then
            echo "✅ Detected: Python unittest"
          fi

          # Detect Storybook
          HAS_STORYBOOK="false"
          if [ -f "package.json" ]; then
            if grep -q '"@storybook' package.json 2>/dev/null; then
              # Check for storybook test runner
              if grep -q '"@storybook/test-runner"' package.json 2>/dev/null || grep -q '"storybook-test"' package.json 2>/dev/null; then
                HAS_STORYBOOK="true"
              fi
            fi
            # Check for .storybook directory
            if [ -d ".storybook" ]; then
              if [ -f "package.json" ] && grep -q '"@storybook/test-runner"' package.json 2>/dev/null; then
                HAS_STORYBOOK="true"
              fi
            fi
          fi
          echo "has_storybook=$HAS_STORYBOOK" >> "$GITHUB_OUTPUT"
          if [ "$HAS_STORYBOOK" = "true" ]; then
            echo "✅ Detected: Storybook"
          fi

  # ==================== PYTEST ====================
  # Test source branch (always fresh, no caching)
  pytest-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_pytest == 'true'
    uses: ./.github/workflows/test-py-pytest.yml
    with:
      ref: ""  # Default checkout = PR branch
      python-version: ${{ inputs.python-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: pytest_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  # Test target branch for pytest
  pytest-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_pytest == 'true'
    uses: ./.github/workflows/test-py-pytest.yml
    with:
      ref: ${{ inputs.target_branch }}
      python-version: ${{ inputs.python-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: pytest_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  # Compare pytest results
  pytest-compare:
    needs: [detect-frameworks, pytest-source, pytest-target]
    if: always() && needs.detect-frameworks.outputs.has_pytest == 'true' && needs.pytest-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: pytest_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: pytest_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.pytest-target.outputs.passed }}
      baseline_total: ${{ needs.pytest-target.outputs.total }}
      baseline_percentage: ${{ needs.pytest-target.outputs.percentage }}
      current_passed: ${{ needs.pytest-source.outputs.passed }}
      current_total: ${{ needs.pytest-source.outputs.total }}
      current_percentage: ${{ needs.pytest-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.pytest-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.pytest-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.pytest-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.pytest-source.outputs.no_tests_found }}
      artifact_name: regression_pytest_${{ github.event.pull_request.number || github.run_id }}

  # ==================== JEST ====================
  # Test source branch with Jest
  jest-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_jest == 'true'
    uses: ./.github/workflows/test-js-jest.yml
    with:
      ref: ""  # Default checkout = PR branch
      node-version: ${{ inputs.node-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: jest_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}
      jest-command: ${{ inputs.jest-command }}
      jest-extra-args: ${{ inputs.jest-extra-args }}
      working-directory: ${{ inputs.working-directory }}

  # Test target branch with Jest
  jest-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_jest == 'true'
    uses: ./.github/workflows/test-js-jest.yml
    with:
      ref: ${{ inputs.target_branch }}
      node-version: ${{ inputs.node-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: jest_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}
      jest-command: ${{ inputs.jest-command }}
      jest-extra-args: ${{ inputs.jest-extra-args }}
      working-directory: ${{ inputs.working-directory }}

  # Compare Jest results
  jest-compare:
    needs: [detect-frameworks, jest-source, jest-target]
    if: always() && needs.detect-frameworks.outputs.has_jest == 'true' && needs.jest-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: jest_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: jest_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.jest-target.outputs.passed }}
      baseline_total: ${{ needs.jest-target.outputs.total }}
      baseline_percentage: ${{ needs.jest-target.outputs.percentage }}
      current_passed: ${{ needs.jest-source.outputs.passed }}
      current_total: ${{ needs.jest-source.outputs.total }}
      current_percentage: ${{ needs.jest-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.jest-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.jest-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.jest-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.jest-source.outputs.no_tests_found }}
      artifact_name: regression_jest_${{ github.event.pull_request.number || github.run_id }}

  # ==================== MOCHA ====================
  # Test source branch with Mocha
  mocha-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_mocha == 'true'
    uses: ./.github/workflows/test-js-mocha.yml
    with:
      ref: ""  # Default checkout = PR branch
      node-version: ${{ inputs.node-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: mocha_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}
      mocha-command: ${{ inputs.mocha-command }}
      mocha-extra-args: ${{ inputs.mocha-extra-args }}
      working-directory: ${{ inputs.working-directory }}

  # Test target branch with Mocha
  mocha-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_mocha == 'true'
    uses: ./.github/workflows/test-js-mocha.yml
    with:
      ref: ${{ inputs.target_branch }}
      node-version: ${{ inputs.node-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: mocha_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}
      mocha-command: ${{ inputs.mocha-command }}
      mocha-extra-args: ${{ inputs.mocha-extra-args }}
      working-directory: ${{ inputs.working-directory }}

  # Compare Mocha results
  mocha-compare:
    needs: [detect-frameworks, mocha-source, mocha-target]
    if: always() && needs.detect-frameworks.outputs.has_mocha == 'true' && needs.mocha-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: mocha_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: mocha_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.mocha-target.outputs.passed }}
      baseline_total: ${{ needs.mocha-target.outputs.total }}
      baseline_percentage: ${{ needs.mocha-target.outputs.percentage }}
      current_passed: ${{ needs.mocha-source.outputs.passed }}
      current_total: ${{ needs.mocha-source.outputs.total }}
      current_percentage: ${{ needs.mocha-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.mocha-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.mocha-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.mocha-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.mocha-source.outputs.no_tests_found }}
      artifact_name: regression_mocha_${{ github.event.pull_request.number || github.run_id }}

  # ==================== RUST/CARGO ====================
  # Test source branch with cargo
  cargo-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_cargo == 'true'
    uses: ./.github/workflows/test-rs-cargo.yml
    with:
      ref: ""  # Default checkout = PR branch
      rust-version: ${{ inputs.rust-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: cargo_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  # Test target branch with cargo
  cargo-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_cargo == 'true'
    uses: ./.github/workflows/test-rs-cargo.yml
    with:
      ref: ${{ inputs.target_branch }}
      rust-version: ${{ inputs.rust-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: cargo_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  # Compare cargo results
  cargo-compare:
    needs: [detect-frameworks, cargo-source, cargo-target]
    if: always() && needs.detect-frameworks.outputs.has_cargo == 'true' && needs.cargo-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: cargo_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: cargo_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.cargo-target.outputs.passed }}
      baseline_total: ${{ needs.cargo-target.outputs.total }}
      baseline_percentage: ${{ needs.cargo-target.outputs.percentage }}
      current_passed: ${{ needs.cargo-source.outputs.passed }}
      current_total: ${{ needs.cargo-source.outputs.total }}
      current_percentage: ${{ needs.cargo-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.cargo-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.cargo-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.cargo-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.cargo-source.outputs.no_tests_found }}
      artifact_name: regression_cargo_${{ github.event.pull_request.number || github.run_id }}

  # ==================== C++ (GTest/CTest) ====================
  # Test C++ source branch
  cpp-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_cpp == 'true'
    uses: ./.github/workflows/test-cpp-gtest.yml
    with:
      ref: ""  # Default checkout = PR branch
      cmake-version: ${{ inputs.cmake-version }}
      compiler: ${{ inputs.cpp-compiler }}
      build-type: ${{ inputs.cpp-build-type }}
      build-dir: ${{ inputs.cpp-build-dir }}
      cmake-args: ${{ inputs.cpp-cmake-args }}
      test-args: ${{ inputs.cpp-test-args }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: cpp_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  # Test C++ target branch
  cpp-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_cpp == 'true'
    uses: ./.github/workflows/test-cpp-gtest.yml
    with:
      ref: ${{ inputs.target_branch }}
      cmake-version: ${{ inputs.cmake-version }}
      compiler: ${{ inputs.cpp-compiler }}
      build-type: ${{ inputs.cpp-build-type }}
      build-dir: ${{ inputs.cpp-build-dir }}
      cmake-args: ${{ inputs.cpp-cmake-args }}
      test-args: ${{ inputs.cpp-test-args }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: cpp_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  # Compare C++ results
  cpp-compare:
    needs: [detect-frameworks, cpp-source, cpp-target]
    if: always() && needs.detect-frameworks.outputs.has_cpp == 'true' && needs.cpp-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: cpp_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: cpp_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.cpp-target.outputs.passed }}
      baseline_total: ${{ needs.cpp-target.outputs.total }}
      baseline_percentage: ${{ needs.cpp-target.outputs.percentage }}
      current_passed: ${{ needs.cpp-source.outputs.passed }}
      current_total: ${{ needs.cpp-source.outputs.total }}
      current_percentage: ${{ needs.cpp-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.cpp-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.cpp-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.cpp-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.cpp-source.outputs.no_tests_found }}
      artifact_name: regression_cpp_${{ github.event.pull_request.number || github.run_id }}

  # ==================== NUNIT (.NET) ====================
  nunit-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_nunit == 'true'
    uses: ./.github/workflows/test-cs-nunit.yml
    with:
      ref: ""
      dotnet-version: ${{ inputs.dotnet-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: nunit_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  nunit-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_nunit == 'true'
    uses: ./.github/workflows/test-cs-nunit.yml
    with:
      ref: ${{ inputs.target_branch }}
      dotnet-version: ${{ inputs.dotnet-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: nunit_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  nunit-compare:
    needs: [detect-frameworks, nunit-source, nunit-target]
    if: always() && needs.detect-frameworks.outputs.has_nunit == 'true' && needs.nunit-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: nunit_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: nunit_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.nunit-target.outputs.passed }}
      baseline_total: ${{ needs.nunit-target.outputs.total }}
      baseline_percentage: ${{ needs.nunit-target.outputs.percentage }}
      current_passed: ${{ needs.nunit-source.outputs.passed }}
      current_total: ${{ needs.nunit-source.outputs.total }}
      current_percentage: ${{ needs.nunit-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.nunit-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.nunit-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.nunit-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.nunit-source.outputs.no_tests_found }}
      artifact_name: regression_nunit_${{ github.event.pull_request.number || github.run_id }}

  # ==================== XUNIT (.NET) ====================
  xunit-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_xunit == 'true'
    uses: ./.github/workflows/test-cs-xunit.yml
    with:
      ref: ""
      dotnet-version: ${{ inputs.dotnet-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: xunit_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  xunit-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_xunit == 'true'
    uses: ./.github/workflows/test-cs-xunit.yml
    with:
      ref: ${{ inputs.target_branch }}
      dotnet-version: ${{ inputs.dotnet-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: xunit_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}

  xunit-compare:
    needs: [detect-frameworks, xunit-source, xunit-target]
    if: always() && needs.detect-frameworks.outputs.has_xunit == 'true' && needs.xunit-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: xunit_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: xunit_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.xunit-target.outputs.passed }}
      baseline_total: ${{ needs.xunit-target.outputs.total }}
      baseline_percentage: ${{ needs.xunit-target.outputs.percentage }}
      current_passed: ${{ needs.xunit-source.outputs.passed }}
      current_total: ${{ needs.xunit-source.outputs.total }}
      current_percentage: ${{ needs.xunit-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.xunit-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.xunit-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.xunit-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.xunit-source.outputs.no_tests_found }}
      artifact_name: regression_xunit_${{ github.event.pull_request.number || github.run_id }}

  # ==================== PYTHON UNITTEST ====================
  unittest-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_unittest == 'true'
    uses: ./.github/workflows/test-py-unittest.yml
    with:
      ref: ""
      python-version: ${{ inputs.python-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: unittest_source_${{ github.event.pull_request.number || github.run_id }}
      start-directory: ${{ inputs.unittest-start-directory }}
      test-pattern: ${{ inputs.unittest-test-pattern }}

  unittest-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_unittest == 'true'
    uses: ./.github/workflows/test-py-unittest.yml
    with:
      ref: ${{ inputs.target_branch }}
      python-version: ${{ inputs.python-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: unittest_target_${{ github.event.pull_request.number || github.run_id }}
      start-directory: ${{ inputs.unittest-start-directory }}
      test-pattern: ${{ inputs.unittest-test-pattern }}

  unittest-compare:
    needs: [detect-frameworks, unittest-source, unittest-target]
    if: always() && needs.detect-frameworks.outputs.has_unittest == 'true' && needs.unittest-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: unittest_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: unittest_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.unittest-target.outputs.passed }}
      baseline_total: ${{ needs.unittest-target.outputs.total }}
      baseline_percentage: ${{ needs.unittest-target.outputs.percentage }}
      current_passed: ${{ needs.unittest-source.outputs.passed }}
      current_total: ${{ needs.unittest-source.outputs.total }}
      current_percentage: ${{ needs.unittest-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.unittest-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.unittest-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.unittest-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.unittest-source.outputs.no_tests_found }}
      artifact_name: regression_unittest_${{ github.event.pull_request.number || github.run_id }}

  # ==================== STORYBOOK ====================
  storybook-source:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_storybook == 'true'
    uses: ./.github/workflows/test-js-storybook.yml
    with:
      ref: ""
      node-version: ${{ inputs.node-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: storybook_source_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}
      storybook_port: ${{ inputs.storybook-port }}
      storybook_start_command: ${{ inputs.storybook-start-command }}
      storybook_test_command: ${{ inputs.storybook-test-command }}

  storybook-target:
    needs: detect-frameworks
    if: needs.detect-frameworks.outputs.has_storybook == 'true'
    uses: ./.github/workflows/test-js-storybook.yml
    with:
      ref: ${{ inputs.target_branch }}
      node-version: ${{ inputs.node-version }}
      runs_on: ${{ inputs.runs_on }}
      artifact_name: storybook_target_${{ github.event.pull_request.number || github.run_id }}
      parallel_workers: ${{ inputs.parallel_workers }}
      storybook_port: ${{ inputs.storybook-port }}
      storybook_start_command: ${{ inputs.storybook-start-command }}
      storybook_test_command: ${{ inputs.storybook-test-command }}

  storybook-compare:
    needs: [detect-frameworks, storybook-source, storybook-target]
    if: always() && needs.detect-frameworks.outputs.has_storybook == 'true' && needs.storybook-source.result == 'success'
    uses: ./.github/workflows/regression-test.yml
    with:
      runs_on: ${{ inputs.runs_on }}
      baseline_label: ${{ inputs.target_branch }}
      baseline_results_artifact: storybook_target_${{ github.event.pull_request.number || github.run_id }}
      baseline_results_filename: test_data.json
      current_label: ${{ github.head_ref || github.ref_name }}
      current_results_artifact: storybook_source_${{ github.event.pull_request.number || github.run_id }}
      current_results_filename: test_data.json
      baseline_passed: ${{ needs.storybook-target.outputs.passed }}
      baseline_total: ${{ needs.storybook-target.outputs.total }}
      baseline_percentage: ${{ needs.storybook-target.outputs.percentage }}
      current_passed: ${{ needs.storybook-source.outputs.passed }}
      current_total: ${{ needs.storybook-source.outputs.total }}
      current_percentage: ${{ needs.storybook-source.outputs.percentage }}
      baseline_collection_errors: ${{ needs.storybook-target.outputs.collection_errors }}
      baseline_no_tests_found: ${{ needs.storybook-target.outputs.no_tests_found }}
      current_collection_errors: ${{ needs.storybook-source.outputs.collection_errors }}
      current_no_tests_found: ${{ needs.storybook-source.outputs.no_tests_found }}
      artifact_name: regression_storybook_${{ github.event.pull_request.number || github.run_id }}

  # ==================== AGGREGATE RESULTS ====================
  aggregate-results:
    needs: [detect-frameworks, pytest-compare, jest-compare, mocha-compare, cargo-compare, cpp-compare, nunit-compare, xunit-compare, unittest-compare, storybook-compare]
    if: always()
    runs-on: ${{ fromJSON(inputs.runs_on) }}
    outputs:
      has_regressions: ${{ steps.aggregate.outputs.has_regressions }}
      regression_count: ${{ steps.aggregate.outputs.regression_count }}
    steps:
      - name: Aggregate regression results
        id: aggregate
        run: |
          TOTAL_REGRESSIONS=0
          HAS_REGRESSIONS="false"

          # Check pytest
          if [ "${{ needs.detect-frameworks.outputs.has_pytest }}" == "true" ]; then
            PYTEST_REGRESSIONS="${{ needs.pytest-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.pytest-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + PYTEST_REGRESSIONS))
              echo "Pytest regressions: $PYTEST_REGRESSIONS"
            fi
          fi

          # Check Jest
          if [ "${{ needs.detect-frameworks.outputs.has_jest }}" == "true" ]; then
            JEST_REGRESSIONS="${{ needs.jest-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.jest-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + JEST_REGRESSIONS))
              echo "Jest regressions: $JEST_REGRESSIONS"
            fi
          fi

          # Check Mocha
          if [ "${{ needs.detect-frameworks.outputs.has_mocha }}" == "true" ]; then
            MOCHA_REGRESSIONS="${{ needs.mocha-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.mocha-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + MOCHA_REGRESSIONS))
              echo "Mocha regressions: $MOCHA_REGRESSIONS"
            fi
          fi

          # Check Cargo
          if [ "${{ needs.detect-frameworks.outputs.has_cargo }}" == "true" ]; then
            CARGO_REGRESSIONS="${{ needs.cargo-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.cargo-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + CARGO_REGRESSIONS))
              echo "Cargo regressions: $CARGO_REGRESSIONS"
            fi
          fi

          # Check C++
          if [ "${{ needs.detect-frameworks.outputs.has_cpp }}" == "true" ]; then
            CPP_REGRESSIONS="${{ needs.cpp-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.cpp-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + CPP_REGRESSIONS))
              echo "C++ regressions: $CPP_REGRESSIONS"
            fi
          fi

          # Check NUnit
          if [ "${{ needs.detect-frameworks.outputs.has_nunit }}" == "true" ]; then
            NUNIT_REGRESSIONS="${{ needs.nunit-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.nunit-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + NUNIT_REGRESSIONS))
              echo "NUnit regressions: $NUNIT_REGRESSIONS"
            fi
          fi

          # Check xUnit
          if [ "${{ needs.detect-frameworks.outputs.has_xunit }}" == "true" ]; then
            XUNIT_REGRESSIONS="${{ needs.xunit-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.xunit-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + XUNIT_REGRESSIONS))
              echo "xUnit regressions: $XUNIT_REGRESSIONS"
            fi
          fi

          # Check Python unittest
          if [ "${{ needs.detect-frameworks.outputs.has_unittest }}" == "true" ]; then
            UNITTEST_REGRESSIONS="${{ needs.unittest-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.unittest-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + UNITTEST_REGRESSIONS))
              echo "Python unittest regressions: $UNITTEST_REGRESSIONS"
            fi
          fi

          # Check Storybook
          if [ "${{ needs.detect-frameworks.outputs.has_storybook }}" == "true" ]; then
            STORYBOOK_REGRESSIONS="${{ needs.storybook-compare.outputs.regression_count || '0' }}"
            if [ "${{ needs.storybook-compare.outputs.has_regressions }}" == "true" ]; then
              HAS_REGRESSIONS="true"
              TOTAL_REGRESSIONS=$((TOTAL_REGRESSIONS + STORYBOOK_REGRESSIONS))
              echo "Storybook regressions: $STORYBOOK_REGRESSIONS"
            fi
          fi

          echo "has_regressions=$HAS_REGRESSIONS" >> "$GITHUB_OUTPUT"
          echo "regression_count=$TOTAL_REGRESSIONS" >> "$GITHUB_OUTPUT"
          echo "Total regressions across all frameworks: $TOTAL_REGRESSIONS"

  # ==================== NOTIFICATIONS ====================
  notify:
    needs: [detect-frameworks, pytest-source, pytest-target, pytest-compare, jest-source, jest-target, jest-compare, mocha-source, mocha-target, mocha-compare, cargo-source, cargo-target, cargo-compare, cpp-source, cpp-target, cpp-compare, nunit-source, nunit-target, nunit-compare, xunit-source, xunit-target, xunit-compare, unittest-source, unittest-target, unittest-compare, storybook-source, storybook-target, storybook-compare, aggregate-results]
    if: always() && needs.aggregate-results.outputs.has_regressions == 'true'
    runs-on: ${{ fromJSON(inputs.runs_on) }}
    steps:
      - name: Send notification
        env:
          WEBHOOK: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          if [ -z "$WEBHOOK" ]; then
            echo "No Discord webhook configured, skipping notification"
            exit 0
          fi

          MSG="**Test Regression Alert**\n"
          MSG+="PR #${{ github.event.pull_request.number }}: ${{ github.event.pull_request.title }}\n"
          MSG+="\`${{ github.head_ref }}\` → \`${{ inputs.target_branch }}\`\n\n"

          # Pytest results
          if [ "${{ needs.detect-frameworks.outputs.has_pytest }}" == "true" ]; then
            MSG+="**Pytest:**\n"
            MSG+="  Source: ${{ needs.pytest-source.outputs.passed }}/${{ needs.pytest-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.pytest-target.outputs.passed }}/${{ needs.pytest-target.outputs.total }}\n"
            if [ "${{ needs.pytest-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.pytest-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # Jest results
          if [ "${{ needs.detect-frameworks.outputs.has_jest }}" == "true" ]; then
            MSG+="**Jest:**\n"
            MSG+="  Source: ${{ needs.jest-source.outputs.passed }}/${{ needs.jest-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.jest-target.outputs.passed }}/${{ needs.jest-target.outputs.total }}\n"
            if [ "${{ needs.jest-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.jest-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # Mocha results
          if [ "${{ needs.detect-frameworks.outputs.has_mocha }}" == "true" ]; then
            MSG+="**Mocha:**\n"
            MSG+="  Source: ${{ needs.mocha-source.outputs.passed }}/${{ needs.mocha-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.mocha-target.outputs.passed }}/${{ needs.mocha-target.outputs.total }}\n"
            if [ "${{ needs.mocha-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.mocha-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # Cargo results
          if [ "${{ needs.detect-frameworks.outputs.has_cargo }}" == "true" ]; then
            MSG+="**Cargo (Rust):**\n"
            MSG+="  Source: ${{ needs.cargo-source.outputs.passed }}/${{ needs.cargo-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.cargo-target.outputs.passed }}/${{ needs.cargo-target.outputs.total }}\n"
            if [ "${{ needs.cargo-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.cargo-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # C++ results
          if [ "${{ needs.detect-frameworks.outputs.has_cpp }}" == "true" ]; then
            MSG+="**C++:**\n"
            MSG+="  Source: ${{ needs.cpp-source.outputs.passed }}/${{ needs.cpp-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.cpp-target.outputs.passed }}/${{ needs.cpp-target.outputs.total }}\n"
            if [ "${{ needs.cpp-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.cpp-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # NUnit results
          if [ "${{ needs.detect-frameworks.outputs.has_nunit }}" == "true" ]; then
            MSG+="**NUnit (.NET):**\n"
            MSG+="  Source: ${{ needs.nunit-source.outputs.passed }}/${{ needs.nunit-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.nunit-target.outputs.passed }}/${{ needs.nunit-target.outputs.total }}\n"
            if [ "${{ needs.nunit-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.nunit-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # xUnit results
          if [ "${{ needs.detect-frameworks.outputs.has_xunit }}" == "true" ]; then
            MSG+="**xUnit (.NET):**\n"
            MSG+="  Source: ${{ needs.xunit-source.outputs.passed }}/${{ needs.xunit-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.xunit-target.outputs.passed }}/${{ needs.xunit-target.outputs.total }}\n"
            if [ "${{ needs.xunit-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.xunit-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # Python unittest results
          if [ "${{ needs.detect-frameworks.outputs.has_unittest }}" == "true" ]; then
            MSG+="**Python unittest:**\n"
            MSG+="  Source: ${{ needs.unittest-source.outputs.passed }}/${{ needs.unittest-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.unittest-target.outputs.passed }}/${{ needs.unittest-target.outputs.total }}\n"
            if [ "${{ needs.unittest-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.unittest-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          # Storybook results
          if [ "${{ needs.detect-frameworks.outputs.has_storybook }}" == "true" ]; then
            MSG+="**Storybook:**\n"
            MSG+="  Source: ${{ needs.storybook-source.outputs.passed }}/${{ needs.storybook-source.outputs.total }}\n"
            MSG+="  Target: ${{ needs.storybook-target.outputs.passed }}/${{ needs.storybook-target.outputs.total }}\n"
            if [ "${{ needs.storybook-compare.outputs.has_regressions }}" == "true" ]; then
              MSG+="  Regressions: ${{ needs.storybook-compare.outputs.regression_count }}\n"
            fi
            MSG+="\n"
          fi

          MSG+="Total Regressions: ${{ needs.aggregate-results.outputs.regression_count }}\n\n"
          MSG+="[View Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})"

          curl -s -H "Content-Type: application/json" \
            -d "{\"content\": \"$(echo -e "$MSG")\"}" \
            "$WEBHOOK" || true
